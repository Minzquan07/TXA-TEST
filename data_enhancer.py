import numpy as np
import random
from collections import Counter
from fileInteractions import save_data, exportConfig, load_data_file
import os

class DataEnhancer:
    def __init__(self):
        self.config = exportConfig()
        
    def enhance_with_patterns(self, auto_merge=True):
        """TÄƒng cÆ°á»ng dá»¯ liá»‡u dá»±a trÃªn pattern phÃ¢n tÃ­ch Ä‘Æ°á»£c"""
        print("ğŸš€ Báº¯t Ä‘áº§u tÄƒng cÆ°á»ng dá»¯ liá»‡u vá»›i pattern...")
        
        # Äáº£m báº£o file dá»¯ liá»‡u tá»“n táº¡i
        data_file = load_data_file()
        print(f"ğŸ“ File dá»¯ liá»‡u: {data_file}")
        
        # Äáº§u tiÃªn, táº¡o dá»¯ liá»‡u cÆ¡ báº£n tá»« file gá»‘c
        base_data = self.load_base_data()
        if base_data:
            print(f"ğŸ“¥ ÄÃ£ táº£i {len(base_data)} chuá»—i tá»« dá»¯ liá»‡u gá»‘c")
        
        # Pattern tá»« phÃ¢n tÃ­ch
        high_accuracy_patterns = [
            # Pattern cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao
            ([15, 9, 10], 8),   # -> Xá»‰u
            ([9, 10, 12], 7),   # -> Xá»‰u  
            ([9, 14, 10], 15),  # -> TÃ i
            ([11, 8, 9], 14),   # -> TÃ i
            ([8, 12, 7], 11),   # -> TÃ i
            ([10, 13, 9], 8),   # -> Xá»‰u
            ([13, 9, 10], 12),  # -> TÃ i
        ]
        
        # Sá»‘ xuáº¥t hiá»‡n nhiá»u nháº¥t tá»« phÃ¢n tÃ­ch
        common_numbers = [11, 9, 10, 12, 8, 7, 13, 14, 6, 15]
        
        enhanced_data = []
        
        # 1. ThÃªm dá»¯ liá»‡u gá»‘c
        enhanced_data.extend(base_data)
        
        # 2. Táº¡o dá»¯ liá»‡u tá»« pattern chÃ­nh xÃ¡c
        print("ğŸ“Š Táº¡o dá»¯ liá»‡u tá»« pattern chÃ­nh xÃ¡c...")
        for pattern, next_val in high_accuracy_patterns:
            # Táº¡o biáº¿n thá»ƒ tá»« pattern gá»‘c
            for _ in range(10):  # TÄƒng sá»‘ biáº¿n thá»ƒ
                variant = self.create_pattern_variant(pattern, common_numbers)
                enhanced_data.append(variant + [next_val])
        
        # 3. Táº¡o dá»¯ liá»‡u tá»« chuá»—i TÃ i/Xá»‰u dÃ i
        print("ğŸ“ˆ Táº¡o dá»¯ liá»‡u tá»« chuá»—i xu hÆ°á»›ng...")
        enhanced_data.extend(self.generate_trend_sequences())
        
        # 4. Táº¡o dá»¯ liá»‡u tá»« phÃ¢n phá»‘i sá»‘ thá»±c táº¿
        print("ğŸ² Táº¡o dá»¯ liá»‡u tá»« phÃ¢n phá»‘i sá»‘...")
        enhanced_data.extend(self.generate_distribution_sequences(common_numbers))
        
        # 5. Táº¡o dá»¯ liá»‡u tá»« phÃ¢n tÃ­ch phiÃªn
        print("â° Táº¡o dá»¯ liá»‡u tá»« phÃ¢n tÃ­ch phiÃªn...")
        enhanced_data.extend(self.generate_session_based_sequences())
        
        # Loáº¡i bá» trÃ¹ng láº·p
        unique_data = []
        seen = set()
        for seq in enhanced_data:
            seq_tuple = tuple(seq)
            if seq_tuple not in seen:
                seen.add(seq_tuple)
                unique_data.append(seq)
        
        enhanced_data = unique_data
        
        # LÆ°u dá»¯ liá»‡u tÄƒng cÆ°á»ng
        if enhanced_data:
            # Äáº£m báº£o thÆ° má»¥c tá»“n táº¡i
            enhanced_file = "enhanced_data.txt"
            os.makedirs(os.path.dirname(enhanced_file) if os.path.dirname(enhanced_file) else ".", exist_ok=True)
            
            # XÃ³a file cÅ© náº¿u tá»“n táº¡i
            if os.path.exists(enhanced_file):
                os.remove(enhanced_file)
                
            for sequence in enhanced_data:
                save_data(sequence, enhanced_file)
            
            print(f"âœ… ÄÃ£ táº¡o {len(enhanced_data)} chuá»—i dá»¯ liá»‡u tÄƒng cÆ°á»ng")
            print(f"ğŸ“ LÆ°u vÃ o: {enhanced_file}")
            
            # Thá»‘ng kÃª dá»¯ liá»‡u tÄƒng cÆ°á»ng
            self.analyze_enhanced_data(enhanced_data)
            
            # Tá»± Ä‘á»™ng merge náº¿u Ä‘Æ°á»£c yÃªu cáº§u
            if auto_merge:
                self.merge_enhanced_data()
                print("ğŸ”„ ÄÃ£ tá»± Ä‘á»™ng merge vÃ o dá»¯ liá»‡u chÃ­nh")
        else:
            print("âŒ KhÃ´ng táº¡o Ä‘Æ°á»£c dá»¯ liá»‡u tÄƒng cÆ°á»ng")
        
        return enhanced_data
    
    def load_base_data(self):
        """Táº£i dá»¯ liá»‡u cÆ¡ báº£n tá»« file gá»‘c"""
        base_data = []
        config = exportConfig()
        data_file = config["data_file"]
        
        # Äáº£m báº£o file tá»“n táº¡i
        if not os.path.exists(data_file):
            print(f"âš ï¸  File {data_file} khÃ´ng tá»“n táº¡i, táº¡o file má»›i...")
            os.makedirs(os.path.dirname(data_file) if os.path.dirname(data_file) else ".", exist_ok=True)
            with open(data_file, 'w') as f:
                # ThÃªm dá»¯ liá»‡u máº«u cÆ¡ báº£n
                sample_data = [
                    [11, 16, 5, 7, 11, 10, 9, 12],
                    [10, 10, 13, 11, 14, 9, 15, 6],
                    [12, 16, 10, 10, 7, 8, 9, 12],
                    [12, 7, 8, 12, 7, 9, 9, 14]
                ]
                for seq in sample_data:
                    f.write(",".join(map(str, seq)) + "\n")
            print(f"âœ… ÄÃ£ táº¡o file {data_file} vá»›i dá»¯ liá»‡u máº«u")
        
        try:
            with open(data_file, "r", encoding='utf-8') as file:
                lines = file.read().splitlines()
                for line in lines:
                    if line.strip():
                        # Xá»­ lÃ½ nhiá»u Ä‘á»‹nh dáº¡ng
                        line_clean = line.replace(' ', ',').replace('\t', ',')
                        numbers = [int(x.strip()) for x in line_clean.split(',') if x.strip()]
                        if len(numbers) >= 5:  # Giáº£m yÃªu cáº§u Ä‘á»™ dÃ i
                            base_data.append(numbers)
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘á»c file {data_file}: {e}")
        
        return base_data
    
    def create_pattern_variant(self, base_pattern, common_numbers):
        """Táº¡o biáº¿n thá»ƒ tá»« pattern gá»‘c"""
        variant = base_pattern.copy()
        
        # Thay Ä‘á»•i ngáº«u nhiÃªn 1-2 sá»‘ trong pattern
        num_changes = random.randint(0, 2)  # CÃ³ thá»ƒ khÃ´ng thay Ä‘á»•i
        for _ in range(num_changes):
            change_pos = random.randint(0, len(variant) - 1)
            # Thay báº±ng sá»‘ phá»• biáº¿n khÃ¡c
            available_nums = [n for n in common_numbers if n != variant[change_pos]]
            if available_nums:
                new_num = random.choice(available_nums)
                variant[change_pos] = new_num
        
        return variant
    
    def generate_trend_sequences(self):
        """Táº¡o chuá»—i dá»±a trÃªn xu hÆ°á»›ng TÃ i/Xá»‰u"""
        sequences = []
        
        # Táº¡o nhiá»u chuá»—i hÆ¡n
        for _ in range(20):  # Giáº£m sá»‘ lÆ°á»£ng Ä‘á»ƒ trÃ¡nh quÃ¡ nhiá»u
            seq_length = random.randint(6, 10)  # Giáº£m Ä‘á»™ dÃ i
            seq = []
            
            # Chá»n xu hÆ°á»›ng ban Ä‘áº§u
            current_trend = random.choice(['tai', 'xiu'])
            
            for i in range(seq_length):
                # CÃ³ 20% kháº£ nÄƒng Ä‘á»•i trend
                if random.random() < 0.2:
                    current_trend = 'xiu' if current_trend == 'tai' else 'tai'
                
                if current_trend == 'tai':
                    seq.append(random.randint(11, 16))
                else:
                    seq.append(random.randint(5, 10))
            sequences.append(seq)
        
        return sequences
    
    def generate_distribution_sequences(self, common_numbers):
        """Táº¡o chuá»—i dá»±a trÃªn phÃ¢n phá»‘i sá»‘ thá»±c táº¿"""
        sequences = []
        
        # Táº§n suáº¥t sá»‘ tá»« phÃ¢n tÃ­ch
        number_weights = {
            11: 150, 9: 150, 10: 140, 12: 140, 8: 120,
            7: 120, 13: 100, 14: 90, 6: 70, 15: 60,
            5: 40, 16: 35, 17: 25, 18: 20, 4: 15, 3: 10
        }
        
        numbers = list(number_weights.keys())
        weights = list(number_weights.values())
        
        for _ in range(30):  # Giáº£m sá»‘ lÆ°á»£ng
            seq_length = random.randint(6, 9)
            seq = []
            for i in range(seq_length):
                num = random.choices(numbers, weights=weights)[0]
                seq.append(num)
            sequences.append(seq)
        
        return sequences
    
    def generate_session_based_sequences(self):
        """Táº¡o chuá»—i dá»±a trÃªn phÃ¢n tÃ­ch phiÃªn"""
        sequences = []
        
        # Táº¡o nhiá»u loáº¡i phiÃªn khÃ¡c nhau
        session_types = [
            ('tai_strong', 0.7, 10),   # PhiÃªn TÃ i máº¡nh
            ('xiu_strong', 0.3, 10),   # PhiÃªn Xá»‰u máº¡nh  
            ('balanced', 0.5, 15),     # PhiÃªn cÃ¢n báº±ng
            ('volatile', 0.45, 10)     # PhiÃªn biáº¿n Ä‘á»™ng
        ]
        
        for session_type, tai_prob, count in session_types:
            for _ in range(count):
                seq_length = random.randint(6, 9)
                seq = []
                for i in range(seq_length):
                    if random.random() < tai_prob:
                        seq.append(random.randint(11, 16))
                    else:
                        seq.append(random.randint(5, 10))
                sequences.append(seq)
        
        return sequences
    
    def analyze_enhanced_data(self, enhanced_data):
        """PhÃ¢n tÃ­ch dá»¯ liá»‡u tÄƒng cÆ°á»ng"""
        print(f"\nğŸ“ˆ PHÃ‚N TÃCH Dá»® LIá»†U TÄ‚NG CÆ¯á»œNG")
        print("=" * 40)
        
        if not enhanced_data:
            print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch")
            return
            
        all_numbers = []
        for seq in enhanced_data:
            all_numbers.extend(seq)
        
        # Thá»‘ng kÃª cÆ¡ báº£n
        total_numbers = len(all_numbers)
        tai_count = sum(1 for x in all_numbers if x > 10.5)
        xiu_count = total_numbers - tai_count
        
        print(f"Tá»•ng sá»‘: {total_numbers}")
        print(f"TÃ i: {tai_count} ({tai_count/total_numbers*100:.1f}%)")
        print(f"Xá»‰u: {xiu_count} ({xiu_count/total_numbers*100:.1f}%)")
        print(f"Trung bÃ¬nh: {np.mean(all_numbers):.2f}")
        
        # Top sá»‘ xuáº¥t hiá»‡n
        number_counts = Counter(all_numbers)
        print(f"\nğŸ”¢ TOP Sá» XUáº¤T HIá»†N:")
        for num, count in number_counts.most_common(8):
            percentage = count / total_numbers * 100
            trend = "TÃ€I" if num > 10.5 else "Xá»ˆU"
            print(f"Sá»‘ {num:2d}: {count:3d} láº§n ({percentage:5.1f}%) - {trend}")
    
    def merge_enhanced_data(self):
        """Merge dá»¯ liá»‡u tÄƒng cÆ°á»ng vÃ o file chÃ­nh"""
        try:
            enhanced_file = "enhanced_data.txt"
            if not os.path.exists(enhanced_file):
                print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {enhanced_file}")
                return
                
            with open(enhanced_file, "r", encoding='utf-8') as f:
                enhanced_lines = f.read().splitlines()
            
            # Äá»c dá»¯ liá»‡u hiá»‡n cÃ³ Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
            existing_data = set()
            config = exportConfig()
            data_file = config["data_file"]
            
            # Äáº£m báº£o file tá»“n táº¡i
            if not os.path.exists(data_file):
                print(f"âš ï¸  File {data_file} khÃ´ng tá»“n táº¡i, táº¡o má»›i...")
                os.makedirs(os.path.dirname(data_file) if os.path.dirname(data_file) else ".", exist_ok=True)
                with open(data_file, 'w', encoding='utf-8') as f:
                    pass
            
            if os.path.exists(data_file):
                with open(data_file, "r", encoding='utf-8') as f:
                    for line in f:
                        existing_data.add(line.strip())
            
            # ThÃªm dá»¯ liá»‡u má»›i
            added_count = 0
            with open(data_file, "a", encoding='utf-8') as f:
                for line in enhanced_lines:
                    if line.strip() and line not in existing_data:
                        if added_count == 0 and len(existing_data) > 0:
                            f.write("\n" + line)
                        else:
                            f.write(line + "\n")
                        added_count += 1
            
            print(f"âœ… ÄÃ£ merge {added_count} chuá»—i má»›i vÃ o dá»¯ liá»‡u chÃ­nh")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi merge dá»¯ liá»‡u: {e}")

# HÃ m tiá»‡n Ã­ch
def enhance_training_data():
    """Cháº¡y tÄƒng cÆ°á»ng dá»¯ liá»‡u"""
    try:
        enhancer = DataEnhancer()
        
        # Há»i ngÆ°á»i dÃ¹ng cÃ³ muá»‘n auto merge khÃ´ng
        auto_merge_input = input("ğŸ¤” CÃ³ tá»± Ä‘á»™ng merge vÃ o dá»¯ liá»‡u chÃ­nh khÃ´ng? (y/n) [máº·c Ä‘á»‹nh: y]: ").strip()
        auto_merge = auto_merge_input.lower() != 'n' if auto_merge_input else True
        
        enhanced_data = enhancer.enhance_with_patterns(auto_merge=auto_merge)
        
        if enhanced_data and auto_merge:
            print("ğŸ” Cháº¡y 'enhanced_train' Ä‘á»ƒ huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u má»›i")
            
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh tÄƒng cÆ°á»ng dá»¯ liá»‡u: {e}")
        return False

# Táº¡o dá»¯ liá»‡u máº«u nhanh
def create_quick_sample_data():
    """Táº¡o dá»¯ liá»‡u máº«u nhanh Ä‘á»ƒ test"""
    sample_data = [
        [11, 16, 5, 7, 11, 10, 9, 12],
        [10, 10, 13, 11, 14, 9, 15, 6],
        [12, 16, 10, 10, 7, 8, 9, 12],
        [12, 7, 8, 12, 7, 9, 9, 14],
        [7, 12, 13, 11, 12, 9, 11, 8],
        [3, 7, 9, 8, 12, 8, 10, 13],
        [9, 10, 17, 8, 6, 5, 9, 9],
        [11, 8, 8, 7, 13, 8, 8, 10]
    ]
    
    config = exportConfig()
    data_file = config["data_file"]
    
    # Äáº£m báº£o thÆ° má»¥c tá»“n táº¡i
    os.makedirs(os.path.dirname(data_file) if os.path.dirname(data_file) else ".", exist_ok=True)
    
    with open(data_file, 'w', encoding='utf-8') as f:
        for seq in sample_data:
            f.write(",".join(map(str, seq)) + "\n")
    
    print(f"âœ… ÄÃ£ táº¡o file {data_file} vá»›i {len(sample_data)} chuá»—i máº«u")
    return sample_data

if __name__ == "__main__":
    # Kiá»ƒm tra xem cÃ³ cáº§n táº¡o dá»¯ liá»‡u máº«u khÃ´ng
    config = exportConfig()
    data_file = config["data_file"]
    
    if not os.path.exists(data_file):
        print("ğŸ“ Táº¡o dá»¯ liá»‡u máº«u...")
        create_quick_sample_data()
    
    enhance_training_data()