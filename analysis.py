import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
from datetime import datetime
import pandas as pd
from fileInteractions import load_actual_results, exportConfig
import os
from pickle import load

plt.rcParams['font.sans-serif'] = ['Arial']
plt.rcParams['axes.unicode_minus'] = False

def analyze_actual_results():
    """Ph√¢n t√≠ch to√†n di·ªán k·∫øt qu·∫£ th·ª±c t·∫ø ƒë√£ l∆∞u"""
    actual_results = load_actual_results()
    
    if not actual_results:
        print("‚ùå Ch∆∞a c√≥ k·∫øt qu·∫£ th·ª±c t·∫ø n√†o ƒë∆∞·ª£c l∆∞u!")
        return
    
    print(f"üìä PH√ÇN T√çCH {len(actual_results)} K·∫æT QU·∫¢ TH·ª∞C T·∫æ")
    print("=" * 50)
    
    # Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ ph√¢n t√≠ch
    df = pd.DataFrame(actual_results)
    
    # 1. Th·ªëng k√™ c∆° b·∫£n
    print("\nüìà TH·ªêNG K√ä C∆† B·∫¢N:")
    print(f"‚Ä¢ T·ªïng s·ªë k·∫øt qu·∫£: {len(df)}")
    print(f"‚Ä¢ Gi√° tr·ªã nh·ªè nh·∫•t: {df['actual'].min()}")
    print(f"‚Ä¢ Gi√° tr·ªã l·ªõn nh·∫•t: {df['actual'].max()}")
    print(f"‚Ä¢ Trung b√¨nh: {df['actual'].mean():.2f}")
    print(f"‚Ä¢ Trung v·ªã: {df['actual'].median()}")
    print(f"‚Ä¢ ƒê·ªô l·ªách chu·∫©n: {df['actual'].std():.2f}")
    
    # 2. Ph√¢n ph·ªëi T√†i/X·ªâu
    tai_count = len(df[df['actual'] > 10.5])
    xiu_count = len(df[df['actual'] <= 10.5])
    total = len(df)
    
    print(f"\nüé≤ PH√ÇN PH·ªêI T√ÄI/X·ªàU:")
    print(f"‚Ä¢ T√†i: {tai_count} ({tai_count/total*100:.1f}%)")
    print(f"‚Ä¢ X·ªâu: {xiu_count} ({xiu_count/total*100:.1f}%)")
    
    # 3. Ph√¢n t√≠ch xu h∆∞·ªõng
    print(f"\nüìä PH√ÇN T√çCH XU H∆Ø·ªöNG:")
    
    # Xu h∆∞·ªõng g·∫ßn ƒë√¢y (10 k·∫øt qu·∫£ cu·ªëi)
    recent = df.tail(min(10, len(df)))
    recent_tai = len(recent[recent['actual'] > 10.5])
    recent_xiu = len(recent[recent['actual'] <= 10.5])
    
    print(f"‚Ä¢ 10 k·∫øt qu·∫£ g·∫ßn nh·∫•t: T√†i {recent_tai}, X·ªâu {recent_xiu}")
    
    # Chu·ªói li√™n ti·∫øp
    consecutive = analyze_consecutive_trends(df)
    print(f"‚Ä¢ Chu·ªói T√†i d√†i nh·∫•t: {consecutive['max_tai']}")
    print(f"‚Ä¢ Chu·ªói X·ªâu d√†i nh·∫•t: {consecutive['max_xiu']}")
    
    # 4. Ph√¢n t√≠ch theo gi√° tr·ªã c·ª• th·ªÉ
    value_analysis = analyze_value_distribution(df)
    print(f"\nüî¢ PH√ÇN T√çCH THEO GI√Å TR·ªä:")
    print(f"‚Ä¢ S·ªë xu·∫•t hi·ªán nhi·ªÅu nh·∫•t: {value_analysis['most_common']}")
    print(f"‚Ä¢ T·∫ßn su·∫•t c√°c s·ªë:")
    for value, count in value_analysis['value_counts'].most_common(5):
        print(f"  {value}: {count} l·∫ßn ({count/total*100:.1f}%)")
    
    # 5. ƒê·ªô ch√≠nh x√°c c·ªßa d·ª± ƒëo√°n (n·∫øu c√≥ th√¥ng tin d·ª± ƒëo√°n)
    if any('predictions' in row for index, row in df.iterrows()):
        accuracy_analysis = analyze_prediction_accuracy(df)
        print(f"\nüéØ ƒê·ªò CH√çNH X√ÅC D·ª∞ ƒêO√ÅN:")
        for model, acc in accuracy_analysis.items():
            print(f"‚Ä¢ {model.upper()}: {acc['accuracy']:.1f}%")
    
    # 6. V·∫Ω bi·ªÉu ƒë·ªì
    plot_analysis_results(df, actual_results)
    
    return df

def analyze_consecutive_trends(df):
    """Ph√¢n t√≠ch chu·ªói li√™n ti·∫øp T√†i/X·ªâu"""
    trends = []
    current_trend = None
    current_length = 0
    max_tai = 0
    max_xiu = 0
    
    for actual in df['actual']:
        trend = 'tai' if actual > 10.5 else 'xiu'
        
        if trend == current_trend:
            current_length += 1
        else:
            if current_trend == 'tai':
                max_tai = max(max_tai, current_length)
            elif current_trend == 'xiu':
                max_xiu = max(max_xiu, current_length)
            
            current_trend = trend
            current_length = 1
    
    # C·∫≠p nh·∫≠t cho chu·ªói cu·ªëi c√πng
    if current_trend == 'tai':
        max_tai = max(max_tai, current_length)
    elif current_trend == 'xiu':
        max_xiu = max(max_xiu, current_length)
    
    return {'max_tai': max_tai, 'max_xiu': max_xiu}

def analyze_value_distribution(df):
    """Ph√¢n t√≠ch ph√¢n ph·ªëi gi√° tr·ªã"""
    value_counts = Counter(df['actual'])
    most_common = value_counts.most_common(1)[0][0] if value_counts else None
    
    return {
        'value_counts': value_counts,
        'most_common': most_common
    }

def analyze_prediction_accuracy(df):
    """Ph√¢n t√≠ch ƒë·ªô ch√≠nh x√°c c·ªßa c√°c model"""
    accuracy_results = {}
    
    for index, row in df.iterrows():
        if 'predictions' in row and row['predictions']:
            actual = row['actual']
            predictions = row['predictions']
            
            for model, pred_value in predictions.items():
                if model not in accuracy_results:
                    accuracy_results[model] = {'correct': 0, 'total': 0}
                
                pred_trend = 'tai' if pred_value > 10.5 else 'xiu'
                actual_trend = 'tai' if actual > 10.5 else 'xiu'
                
                accuracy_results[model]['total'] += 1
                if pred_trend == actual_trend:
                    accuracy_results[model]['correct'] += 1
    
    # T√≠nh ph·∫ßn trƒÉm ch√≠nh x√°c
    for model, stats in accuracy_results.items():
        if stats['total'] > 0:
            stats['accuracy'] = (stats['correct'] / stats['total']) * 100
        else:
            stats['accuracy'] = 0
    
    return accuracy_results

def plot_analysis_results(df, actual_results):
    """V·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√≠ch k·∫øt qu·∫£"""
    if len(df) < 5:
        print("üìä Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì")
        return
        
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('PH√ÇN T√çCH K·∫æT QU·∫¢ TH·ª∞C T·∫æ', fontsize=16, fontweight='bold')
    
    # 1. Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi T√†i/X·ªâu
    tai_xiu_counts = [len(df[df['actual'] > 10.5]), len(df[df['actual'] <= 10.5])]
    axes[0, 0].pie(tai_xiu_counts, labels=['T√†i', 'X·ªâu'], autopct='%1.1f%%', colors=['#ff6b6b', '#4ecdc4'])
    axes[0, 0].set_title('PH√ÇN PH·ªêI T√ÄI/X·ªàU')
    
    # 2. Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi gi√° tr·ªã
    value_counts = Counter(df['actual'])
    values = list(value_counts.keys())
    counts = list(value_counts.values())
    
    axes[0, 1].bar(values, counts, color='skyblue', alpha=0.7)
    axes[0, 1].set_xlabel('Gi√° tr·ªã')
    axes[0, 1].set_ylabel('S·ªë l·∫ßn xu·∫•t hi·ªán')
    axes[0, 1].set_title('PH√ÇN PH·ªêI GI√Å TR·ªä')
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. Bi·ªÉu ƒë·ªì xu h∆∞·ªõng theo th·ªùi gian
    trends = ['T√†i' if x > 10.5 else 'X·ªâu' for x in df['actual']]
    trend_numeric = [1 if x == 'T√†i' else 0 for x in trends]
    
    axes[1, 0].plot(range(len(trend_numeric)), trend_numeric, 'o-', alpha=0.7, linewidth=2)
    axes[1, 0].set_xlabel('Th·ª© t·ª± k·∫øt qu·∫£')
    axes[1, 0].set_ylabel('Xu h∆∞·ªõng (1=T√†i, 0=X·ªâu)')
    axes[1, 0].set_title('XU H∆Ø·ªöNG THEO TH·ªúI GIAN')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_yticks([0, 1])
    axes[1, 0].set_yticklabels(['X·ªâu', 'T√†i'])
    
    # 4. Bi·ªÉu ƒë·ªì ƒë·ªô ch√≠nh x√°c model
    if any('predictions' in row for index, row in df.iterrows()):
        accuracy_analysis = analyze_prediction_accuracy(df)
        models = list(accuracy_analysis.keys())
        accuracies = [accuracy_analysis[model]['accuracy'] for model in models]
        
        bars = axes[1, 1].bar(models, accuracies, color=['#ff9ff3', '#f368e0', '#ff6b6b', '#ee5a24', '#00d2d3', '#54a0ff'])
        axes[1, 1].set_xlabel('Model')
        axes[1, 1].set_ylabel('ƒê·ªô ch√≠nh x√°c (%)')
        axes[1, 1].set_title('ƒê·ªò CH√çNH X√ÅC C√ÅC MODEL')
        axes[1, 1].grid(True, alpha=0.3)
        
        # Th√™m gi√° tr·ªã tr√™n m·ªói c·ªôt
        for bar, accuracy in zip(bars, accuracies):
            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                           f'{accuracy:.1f}%', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('analysis_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nüìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì ph√¢n t√≠ch v√†o: analysis_results.png")

def analyze_recent_performance(days=7):
    """Ph√¢n t√≠ch hi·ªáu su·∫•t g·∫ßn ƒë√¢y"""
    actual_results = load_actual_results()
    
    if not actual_results:
        print("‚ùå Ch∆∞a c√≥ k·∫øt qu·∫£ th·ª±c t·∫ø n√†o ƒë∆∞·ª£c l∆∞u!")
        return
    
    df = pd.DataFrame(actual_results)
    
    # L·∫•y k·∫øt qu·∫£ g·∫ßn ƒë√¢y
    recent_df = df.tail(min(days * 10, len(df)))
    
    print(f"\nüìà PH√ÇN T√çCH HI·ªÜU SU·∫§T {len(recent_df)} K·∫æT QU·∫¢ G·∫¶N ƒê√ÇY")
    print("=" * 50)
    
    tai_count = len(recent_df[recent_df['actual'] > 10.5])
    xiu_count = len(recent_df[recent_df['actual'] <= 10.5])
    total = len(recent_df)
    
    print(f"‚Ä¢ T√†i: {tai_count} ({tai_count/total*100:.1f}%)")
    print(f"‚Ä¢ X·ªâu: {xiu_count} ({xiu_count/total*100:.1f}%)")
    
    # Ph√¢n t√≠ch l·ª£i nhu·∫≠n gi·∫£ ƒë·ªãnh
    print(f"\nüí∞ PH√ÇN T√çCH L·ª¢I NHU·∫¨N GI·∫¢ ƒê·ªäNH:")
    print(f"‚Ä¢ T·ª∑ l·ªá th·∫Øng: {max(tai_count, xiu_count)/total*100:.1f}%")
    print(f"‚Ä¢ L·ª£i nhu·∫≠n ti·ªÅm nƒÉng: {(max(tai_count, xiu_count) - min(tai_count, xiu_count)) / total * 100:.1f}%")

def export_analysis_report():
    """Xu·∫•t b√°o c√°o ph√¢n t√≠ch chi ti·∫øt"""
    actual_results = load_actual_results()
    
    if not actual_results:
        print("‚ùå Ch∆∞a c√≥ k·∫øt qu·∫£ th·ª±c t·∫ø n√†o ƒë∆∞·ª£c l∆∞u!")
        return
    
    df = pd.DataFrame(actual_results)
    
    # T·∫°o b√°o c√°o
    report = f"""
B√ÅO C√ÅO PH√ÇN T√çCH K·∫æT QU·∫¢ TH·ª∞C T·∫æ
================================

T·ªïng s·ªë k·∫øt qu·∫£: {len(df)}
Th·ªùi gian ph√¢n t√≠ch: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

TH·ªêNG K√ä C∆† B·∫¢N:
- Gi√° tr·ªã trung b√¨nh: {df['actual'].mean():.2f}
- Gi√° tr·ªã trung v·ªã: {df['actual'].median()}
- ƒê·ªô l·ªách chu·∫©n: {df['actual'].std():.2f}
- Min-Max: {df['actual'].min()} - {df['actual'].max()}

PH√ÇN PH·ªêI T√ÄI/X·ªàU:
- T√†i: {len(df[df['actual'] > 10.5])} ({len(df[df['actual'] > 10.5])/len(df)*100:.1f}%)
- X·ªâu: {len(df[df['actual'] <= 10.5])} ({len(df[df['actual'] <= 10.5])/len(df)*100:.1f}%)

S·ªê XU·∫§T HI·ªÜN NHI·ªÄU NH·∫§T:
"""
    
    value_counts = Counter(df['actual'])
    for value, count in value_counts.most_common(10):
        report += f"    - {value}: {count} l·∫ßn ({count/len(df)*100:.1f}%)\n"
    
    # L∆∞u b√°o c√°o
    with open('analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("‚úÖ ƒê√£ xu·∫•t b√°o c√°o ph√¢n t√≠ch v√†o: analysis_report.txt")
    return report

def compare_with_historical():
    """So s√°nh v·ªõi d·ªØ li·ªáu l·ªãch s·ª≠"""
    config = exportConfig()
    historical_file = config["data_file"]
    
    # Load d·ªØ li·ªáu l·ªãch s·ª≠
    try:
        with open(historical_file, "r") as file:
            historical_data = []
            for line in file.read().splitlines():
                if line.strip():
                    numbers = [int(e.strip()) for e in line.replace('\t', ',').replace(' ', ',').split(',') if e.strip()]
                    historical_data.extend(numbers)
    except FileNotFoundError:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file l·ªãch s·ª≠: {historical_file}")
        return
    
    # Load k·∫øt qu·∫£ th·ª±c t·∫ø
    actual_results = load_actual_results()
    if not actual_results:
        print("‚ùå Ch∆∞a c√≥ k·∫øt qu·∫£ th·ª±c t·∫ø n√†o ƒë∆∞·ª£c l∆∞u!")
        return
    
    actual_values = [result['actual'] for result in actual_results]
    
    print(f"\nüìä SO S√ÅNH V·ªöI D·ªÆ LI·ªÜU L·ªäCH S·ª¨")
    print("=" * 40)
    print(f"‚Ä¢ D·ªØ li·ªáu l·ªãch s·ª≠: {len(historical_data)} s·ªë")
    print(f"‚Ä¢ K·∫øt qu·∫£ th·ª±c t·∫ø: {len(actual_values)} s·ªë")
    
    # So s√°nh ph√¢n ph·ªëi
    hist_tai = len([x for x in historical_data if x > 10.5])
    hist_xiu = len([x for x in historical_data if x <= 10.5])
    actual_tai = len([x for x in actual_values if x > 10.5])
    actual_xiu = len([x for x in actual_values if x <= 10.5])
    
    print(f"\nüé≤ SO S√ÅNH PH√ÇN PH·ªêI:")
    print(f"‚Ä¢ L·ªãch s·ª≠ - T√†i: {hist_tai/len(historical_data)*100:.1f}%")
    print(f"‚Ä¢ Th·ª±c t·∫ø - T√†i: {actual_tai/len(actual_values)*100:.1f}%")
    print(f"‚Ä¢ L·ªãch s·ª≠ - X·ªâu: {hist_xiu/len(historical_data)*100:.1f}%")
    print(f"‚Ä¢ Th·ª±c t·∫ø - X·ªâu: {actual_xiu/len(actual_values)*100:.1f}%")

def analyze_patterns():
    """Ph√¢n t√≠ch pattern th∆∞·ªùng g·∫∑p trong d·ªØ li·ªáu Sunwin"""
    config = exportConfig()
    data_file = config["data_file"]
    
    print("üéØ Ph√¢n t√≠ch pattern d·ªØ li·ªáu Sunwin...")
    print("üîç PH√ÇN T√çCH PATTERN D·ªÆ LI·ªÜU SUNWIN")
    print("=" * 60)
    
    # Load d·ªØ li·ªáu
    daily_data = []
    with open(data_file, "r") as file:
        lines = file.read().splitlines()
        for i, line in enumerate(lines):
            if line.strip():
                numbers = [int(x.strip()) for x in line.replace(' ', ',').split(',') if x.strip()]
                daily_data.append({
                    'day': i + 1,
                    'data': numbers,
                    'count': len(numbers)
                })
    
    print(f"üìÖ T·ªïng s·ªë ng√†y: {len(daily_data)}")
    
    # 1. Ph√¢n t√≠ch t·ªïng quan t·ª´ng ng√†y
    print(f"\nüìä TH·ªêNG K√ä T·ª™NG NG√ÄY:")
    for day_info in daily_data:
        day_data = day_info['data']
        tai_count = sum(1 for x in day_data if x > 10.5)
        xiu_count = len(day_data) - tai_count
        avg_value = sum(day_data) / len(day_data)
        
        print(f"Ng√†y {day_info['day']:2d}: {len(day_data):3d} k·∫øt qu·∫£ | "
              f"T√†i: {tai_count:2d} ({tai_count/len(day_data)*100:4.1f}%) | "
              f"X·ªâu: {xiu_count:2d} | TB: {avg_value:5.2f}")
    
    # 2. Ph√¢n t√≠ch pattern theo chu·ªói
    print(f"\nüéØ PH√ÇN T√çCH PATTERN THEO CHU·ªñI:")
    
    all_patterns = {}
    pattern_length = 3
    
    for day_info in daily_data:
        data = day_info['data']
        for i in range(len(data) - pattern_length):
            pattern = tuple(data[i:i+pattern_length])
            next_val = data[i+pattern_length]
            
            if pattern not in all_patterns:
                all_patterns[pattern] = []
            all_patterns[pattern].append(next_val)
    
    # T√¨m pattern ph·ªï bi·∫øn v√† ƒë·ªô ch√≠nh x√°c
    pattern_stats = []
    for pattern, next_values in all_patterns.items():
        if len(next_values) >= 2:  # Ch·ªâ x√©t pattern xu·∫•t hi·ªán √≠t nh·∫•t 2 l·∫ßn
            avg_next = sum(next_values) / len(next_values)
            tai_count = sum(1 for x in next_values if x > 10.5)
            accuracy = max(tai_count, len(next_values) - tai_count) / len(next_values)
            
            pattern_stats.append({
                'pattern': pattern,
                'frequency': len(next_values),
                'avg_next': avg_next,
                'tai_ratio': tai_count / len(next_values),
                'accuracy': accuracy,
                'trend': 'T√ÄI' if avg_next > 10.5 else 'X·ªàU'
            })
    
    # S·∫Øp x·∫øp theo ƒë·ªô ph·ªï bi·∫øn
    pattern_stats.sort(key=lambda x: x['frequency'], reverse=True)
    
    print(f"\nüèÜ TOP 10 PATTERN PH·ªî BI·∫æN NH·∫§T:")
    print("Pattern       | S·ªë l·∫ßn | T·ªâ l·ªá T√†i | ƒê·ªô ch√≠nh x√°c | Xu h∆∞·ªõng")
    print("-" * 65)
    
    for i, stat in enumerate(pattern_stats[:10]):
        pattern_str = '-'.join(map(str, stat['pattern']))
        print(f"{pattern_str:12} | {stat['frequency']:6d} | {stat['tai_ratio']:8.1%} | {stat['accuracy']:11.1%} | {stat['trend']}")
    
    # 3. Ph√¢n t√≠ch pattern ƒë·∫∑c bi·ªát
    print(f"\nüîç PATTERN ƒê·∫∂C BI·ªÜT:")
    
    # Pattern chu·ªói T√†i/X·ªâu li√™n ti·∫øp
    for day_info in daily_data:
        data = day_info['data']
        trends = ['T' if x > 10.5 else 'X' for x in data]
        
        # T√¨m chu·ªói d√†i nh·∫•t
        max_tai_streak = find_max_streak(trends, 'T')
        max_xiu_streak = find_max_streak(trends, 'X')
        
        if max_tai_streak >= 5 or max_xiu_streak >= 5:
            print(f"Ng√†y {day_info['day']}: Chu·ªói T√†i d√†i {max_tai_streak}, Chu·ªói X·ªâu d√†i {max_xiu_streak}")
    
    # 4. Ph√¢n t√≠ch theo khung gi·∫£ ƒë·ªãnh (chia ng√†y th√†nh c√°c phi√™n)
    print(f"\n‚è∞ PH√ÇN T√çCH THEO PHI√äN GI·∫¢ ƒê·ªäNH:")
    
    for day_info in daily_data[:3]:  # Ph√¢n t√≠ch 3 ng√†y ƒë·∫ßu
        data = day_info['data']
        session_size = 20  # Gi·∫£ ƒë·ªãnh 20 k·∫øt qu·∫£/phi√™n
        
        for session in range(0, len(data), session_size):
            session_data = data[session:session+session_size]
            if len(session_data) >= 10:  # Ch·ªâ x√©t phi√™n ƒë·ªß d√†i
                tai_count = sum(1 for x in session_data if x > 10.5)
                avg_val = sum(session_data) / len(session_data)
                
                print(f"Ng√†y {day_info['day']} - Phi√™n {session//session_size + 1}: "
                      f"T√†i {tai_count}/{len(session_data)} | TB: {avg_val:.2f}")
    
    # 5. Ph√¢n t√≠ch s·ªë xu·∫•t hi·ªán nhi·ªÅu nh·∫•t
    all_numbers = []
    for day_info in daily_data:
        all_numbers.extend(day_info['data'])
    
    number_counts = Counter(all_numbers)
    
    print(f"\nüî¢ TOP S·ªê XU·∫§T HI·ªÜN NHI·ªÄU NH·∫§T:")
    for number, count in number_counts.most_common(10):
        percentage = count / len(all_numbers) * 100
        trend = "T√ÄI" if number > 10.5 else "X·ªàU"
        print(f"S·ªë {number:2d}: {count:3d} l·∫ßn ({percentage:5.1f}%) - {trend}")
    
    # 6. Xu·∫•t pattern quan tr·ªçng
    export_important_patterns(pattern_stats)

def find_max_streak(trends, target):
    """T√¨m chu·ªói d√†i nh·∫•t c·ªßa target trend"""
    max_streak = 0
    current_streak = 0
    
    for trend in trends:
        if trend == target:
            current_streak += 1
            max_streak = max(max_streak, current_streak)
        else:
            current_streak = 0
    
    return max_streak

def export_important_patterns(pattern_stats):
    """Xu·∫•t c√°c pattern quan tr·ªçng"""
    important_patterns = []
    
    # Pattern c√≥ ƒë·ªô ch√≠nh x√°c cao
    high_accuracy = [p for p in pattern_stats if p['accuracy'] >= 0.7]
    high_frequency = [p for p in pattern_stats if p['frequency'] >= 3]
    
    print(f"\nüíé PATTERN QUAN TR·ªåNG:")
    print(f"‚Ä¢ Pattern c√≥ ƒë·ªô ch√≠nh x√°c ‚â•70%: {len(high_accuracy)}")
    print(f"‚Ä¢ Pattern xu·∫•t hi·ªán ‚â•3 l·∫ßn: {len(high_frequency)}")
    
    # Xu·∫•t file pattern
    with open('sunwin_patterns.txt', 'w', encoding='utf-8') as f:
        f.write("PATTERN QUAN TR·ªåNG SUNWIN\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("PATTERN ƒê·ªò CH√çNH X√ÅC CAO (‚â•70%):\n")
        for pattern in sorted(high_accuracy, key=lambda x: x['accuracy'], reverse=True)[:10]:
            pattern_str = '-'.join(map(str, pattern['pattern']))
            f.write(f"{pattern_str} -> {pattern['trend']} (ƒê·ªô ch√≠nh x√°c: {pattern['accuracy']:.1%}, S·ªë l·∫ßn: {pattern['frequency']})\n")
        
        f.write("\nPATTERN PH·ªî BI·∫æN (‚â•3 l·∫ßn):\n")
        for pattern in sorted(high_frequency, key=lambda x: x['frequency'], reverse=True)[:10]:
            pattern_str = '-'.join(map(str, pattern['pattern']))
            f.write(f"{pattern_str} -> {pattern['trend']} (S·ªë l·∫ßn: {pattern['frequency']}, ƒê·ªô ch√≠nh x√°c: {pattern['accuracy']:.1%})\n")
    
    print("‚úÖ ƒê√£ xu·∫•t pattern v√†o: sunwin_patterns.txt")

# H√†m ch√≠nh ƒë·ªÉ ch·∫°y ph√¢n t√≠ch
def run_complete_analysis():
    """Ch·∫°y ph√¢n t√≠ch ho√†n ch·ªânh"""
    print("üîç B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH K·∫æT QU·∫¢ TH·ª∞C T·∫æ...")
    df = analyze_actual_results()
    analyze_recent_performance()
    compare_with_historical()
    export_analysis_report()
    
    return df

if __name__ == "__main__":
    run_complete_analysis()