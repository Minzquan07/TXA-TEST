from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from xgboost import XGBRegressor
from fileInteractions import exportConfig, updateConfig, save_actual_result
import pickle
import numpy as np
import os
from pickle import dump, load

# Táº¡o thÆ° má»¥c models náº¿u chÆ°a tá»“n táº¡i
if not os.path.exists("models"):
    os.makedirs("models")

def train(fileLocation=None):
    """Huáº¥n luyá»‡n táº¥t cáº£ cÃ¡c model"""
    if fileLocation is None:
        config = exportConfig()
        fileLocation = config["data_file"]
    
    config = exportConfig()
    input_length = config["input_length"]
    train_data = {"x": [], "y": []}
    
    print("ğŸ”„ Äang táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u...")
    with open(fileLocation, "r+") as file:
        datasets = file.read().splitlines()
        for dataset in datasets:
            if dataset.strip():
                numbers = [int(e) for e in dataset.split(",")]
                for i in range(len(numbers) - input_length - 1):
                    train_data["x"].append(numbers[i : i + input_length])
                    train_data["y"].append(numbers[i + input_length])
    
    print(f"ğŸ“Š Sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n: {len(train_data['x'])}")
    
    # 1. Random Forest
    print("ğŸŒ² Äang huáº¥n luyá»‡n Random Forest...")
    randomForest = RandomForestRegressor(n_estimators=config["trees_in_the_forest"])
    randomForest.fit(train_data["x"], train_data["y"])
    with open("models/rf.pkl", "wb") as file:
        pickle.dump(randomForest, file)
    print("âœ… ÄÃ£ lÆ°u model Random Forest!")
    
    # 2. SVR
    print("ğŸ” Äang huáº¥n luyá»‡n SVR...")
    svr = SVR(kernel=config["kernel"])
    svr.fit(train_data["x"], train_data["y"])
    with open("models/svr.pkl", "wb") as file:
        pickle.dump(svr, file)
    print("âœ… ÄÃ£ lÆ°u model SVR!")
    
    # 3. Neural Network
    print("ğŸ§  Äang huáº¥n luyá»‡n Neural Network...")
    neural = MLPRegressor(hidden_layer_sizes=(100, 100), activation='relu', solver='adam', max_iter=1000)
    neural.fit(train_data["x"], train_data["y"])
    with open("models/nn.pkl", "wb") as file:
        pickle.dump(neural, file)
    print("âœ… ÄÃ£ lÆ°u model Neural Network!")
    
    # 4. XGBoost
    print("ğŸš€ Äang huáº¥n luyá»‡n XGBoost...")
    xgb = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1)
    xgb.fit(train_data["x"], train_data["y"])
    with open("models/xgb.pkl", "wb") as file:
        pickle.dump(xgb, file)
    print("âœ… ÄÃ£ lÆ°u model XGBoost!")
    
    # 5. Linear Regression
    print("ğŸ“ˆ Äang huáº¥n luyá»‡n Linear Regression...")
    lr = LinearRegression()
    lr.fit(train_data["x"], train_data["y"])
    with open("models/lr.pkl", "wb") as file:
        pickle.dump(lr, file)
    print("âœ… ÄÃ£ lÆ°u model Linear Regression!")
    
    # 6. Gradient Boosting
    print("ğŸ“Š Äang huáº¥n luyá»‡n Gradient Boosting...")
    gb = GradientBoostingRegressor(n_estimators=100, max_depth=4)
    gb.fit(train_data["x"], train_data["y"])
    with open("models/gb.pkl", "wb") as file:
        pickle.dump(gb, file)
    print("âœ… ÄÃ£ lÆ°u model Gradient Boosting!")

def test(testcase):
    """Kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c trÃªn dá»¯ liá»‡u test"""
    config = exportConfig()
    input_length = config["input_length"]
    test_data = {"x": [], "y": []}

    for i in range(len(testcase) - input_length - 1):
        test_data["x"].append(testcase[i : i + input_length])
        test_data["y"].append(testcase[i + input_length])

    models = {}
    accuracy = {}
    
    # Load models
    model_files = ["rf", "svr", "nn", "xgb", "lr", "gb"]
    for model_name in model_files:
        try:
            with open(f"models/{model_name}.pkl", "rb") as file:
                models[model_name] = pickle.load(file)
        except FileNotFoundError:
            print(f"âš ï¸  Model {model_name} chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n")
            continue

    print("ğŸ¯ ÄÃNH GIÃ Äá»˜ CHÃNH XÃC")
    print("=" * 50)
    
    for model_name, model in models.items():
        predictions = model.predict(test_data["x"])
        accuracy[model_name] = r2_score(test_data["y"], predictions)
        mae_score = mean_absolute_error(test_data["y"], predictions)
        
        print(f"{model_name.upper():>20} | RÂ²: {accuracy[model_name]:.4f} | MAE: {mae_score:.4f}")

    # TÃ¬m model tá»‘t nháº¥t
    if accuracy:
        best_model = max(accuracy, key=accuracy.get)
        print(f"\nğŸ† MODEL Tá»T NHáº¤T: {best_model.upper()} (RÂ² = {accuracy[best_model]:.4f})")
    
    return accuracy

def ktest(fileLocation, testcase):
    """Kiá»ƒm tra cÃ¡c kernel khÃ¡c nhau cho SVR"""
    config = exportConfig()
    input_length = config["input_length"]
    test_data = {"x": [], "y": []}
    train_data = {"x": [], "y": []}

    for i in range(len(testcase) - input_length - 1):
        test_data["x"].append(testcase[i : i + input_length])
        test_data["y"].append(testcase[i + input_length])
    
    with open(fileLocation, "r+") as file:
        datasets = file.read().splitlines()
        for dataset in datasets:
            if dataset.strip():
                numbers = [int(e) for e in dataset.split(",")]
                for i in range(len(numbers) - input_length - 1):
                    train_data["x"].append(numbers[i : i + input_length])
                    train_data["y"].append(numbers[i + input_length])

    accuracy = {}
    print("ğŸ” KIá»‚M TRA KERNEL SVR")
    print("=" * 30)

    for kernel in ("linear", "poly", "rbf", "sigmoid"):
        svr = SVR(kernel=kernel)
        svr.fit(train_data["x"], train_data["y"])
        prediction = svr.predict(test_data["x"])
        accuracy[kernel] = round(r2_score(test_data["y"], prediction), 4)
        print(f"{kernel:>10} : {accuracy[kernel]:.4f}")

    # Cáº­p nháº­t kernel tá»‘t nháº¥t vÃ o config
    best_kernel = max(accuracy, key=accuracy.get)
    config = exportConfig()
    config["kernel"] = best_kernel
    updateConfig(config)
    print(f"âœ… ÄÃ£ cáº­p nháº­t kernel tá»‘t nháº¥t: {best_kernel}")

    return accuracy

def s_predict(inp, model_name):
    """Dá»± Ä‘oÃ¡n tá»« model cá»¥ thá»ƒ"""
    try:
        with open(f"models/{model_name}.pkl", "rb") as file:
            model = pickle.load(file)
            return model.predict([inp])
    except FileNotFoundError:
        print(f"âŒ Model {model_name} chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n")
        return None

def calculate_confidence(predictions, ensemble_result):
    """TÃ­nh Ä‘á»™ tin cáº­y dá»±a trÃªn sá»± Ä‘á»“ng thuáº­n"""
    same_direction = 0
    total_models = len(predictions)
    
    for pred in predictions.values():
        if (pred > 10.5 and ensemble_result > 10.5) or (pred <= 10.5 and ensemble_result <= 10.5):
            same_direction += 1
    
    return (same_direction / total_models) * 100

def weighted_ensemble_predict(inp, weights=None):
    """Dá»± Ä‘oÃ¡n káº¿t há»£p cÃ³ trá»ng sá»‘"""
    if weights is None:
        weights = {"rf": 0.25, "xgb": 0.25, "gb": 0.2, "nn": 0.15, "svr": 0.1, "lr": 0.05}
    
    predictions = {}
    total_weight = 0
    weighted_sum = 0
    
    for model_name, weight in weights.items():
        pred = s_predict(inp, model_name)
        if pred is not None:
            pred_value = pred[0]
            predictions[model_name] = pred_value
            weighted_sum += pred_value * weight
            total_weight += weight
    
    if total_weight == 0:
        return None, {}
    
    return weighted_sum / total_weight, predictions

def enhanced_predict(inp, ml):
    """HÃ m dá»± Ä‘oÃ¡n nÃ¢ng cao - tÆ°Æ¡ng thÃ­ch vá»›i hÃ m predict gá»‘c"""
    inp = [int(e) for e in inp] if isinstance(inp, list) else [int(inp)]
    
    if ml == "all":
        res = {}
        for model_name in ["svr", "rf", "nn", "xgb", "lr", "gb"]:
            pred = s_predict(inp, model_name)
            if pred is not None:
                res[model_name] = pred[0]
        
        if not res:
            print("âŒ KhÃ´ng cÃ³ model nÃ o kháº£ dá»¥ng. HÃ£y cháº¡y train trÆ°á»›c!")
            return False
            
        print("Káº¿t quáº£ dá»± Ä‘oÃ¡n:")
        for model_name, pred in res.items():
            trend = "TÃ i" if pred > 10.5 else "Xá»‰u"
            print(f"{model_name} : {pred:.4f} -> {trend}")
        
        # Hiá»ƒn thá»‹ dÃ²ng Ä‘á»ƒ nháº­p káº¿t quáº£ thá»±c táº¿
        print("káº¿t quáº£ Ä‘Ãºng: ", end="", flush=True)
        
        return {"input": inp, "predictions": res}
        
    elif ml == "ensemble":
        result, all_preds = weighted_ensemble_predict(inp)
        if result is None:
            print("âŒ KhÃ´ng cÃ³ model nÃ o kháº£ dá»¥ng. HÃ£y cháº¡y train trÆ°á»›c!")
            return False
            
        print("\nğŸ² Káº¾T QUáº¢ Dá»° ÄOÃN Tá»ª Táº¤T Cáº¢ MODELS")
        print("=" * 45)
        for model_name, pred in all_preds.items():
            trend = "TÃ i" if pred > 10.5 else "Xá»‰u"
            print(f"{model_name.upper():>15} : {pred:7.4f} -> {trend}")
        
        print("=" * 45)
        print(f"ğŸ¯ Káº¾T QUáº¢ Tá»”NG Há»¢P: {result:.4f}")
        
        # PhÃ¢n tÃ­ch káº¿t quáº£
        confidence = calculate_confidence(all_preds, result)
        final_trend = "TÃ i" if result > 10.5 else "Xá»‰u"
        
        print(f"ğŸ“ˆ XU HÆ¯á»šNG CHUNG: {final_trend}")
        print(f"âœ… Äá»˜ TIN Cáº¬Y: {confidence:.1f}%")
        
        # Khuyáº¿n nghá»‹
        print(f"\nğŸ’¡ KHUYáº¾N NGHá»Š:")
        if 10.25 < result < 10.75:
            print("âš ï¸  Bá» LÆ¯á»¢T NÃ€Y (vÃ¹ng khÃ´ng cháº¯c cháº¯n)")
        elif result > 10.75:
            print("ğŸ¯ NÃŠN CHá»ŒN TÃ€I")
        else:
            print("ğŸ¯ NÃŠN CHá»ŒN Xá»ˆU")
        
        # Hiá»ƒn thá»‹ dÃ²ng Ä‘á»ƒ nháº­p káº¿t quáº£ thá»±c táº¿
        print("\nkáº¿t quáº£ Ä‘Ãºng: ", end="", flush=True)
        
        return {"input": inp, "predictions": all_preds, "ensemble": result}
        
    elif ml in ["svr", "rf", "nn", "xgb", "lr", "gb"]:
        res = s_predict(inp, ml)
        if res is None:
            print(f"âŒ Model {ml} chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y cháº¡y train trÆ°á»›c!")
            return False
            
        print(f"\n[{ml.upper()}] Káº¾T QUáº¢ Dá»° ÄOÃN: {res[0]:.4f}")
        
        # Giá»¯ nguyÃªn logic khuyáº¿n nghá»‹ gá»‘c
        if 10.25 < res[0] < 10.75:
            print("âš ï¸  Báº¡n nÃªn bá» lÆ°á»£t nÃ y")
        elif res[0] > 10.75:
            print("ğŸ¯ Kháº£ nÄƒng ra TÃ i lÃ  cao hÆ¡n")
        else:
            print("ğŸ¯ Kháº£ nÄƒng ra Xá»‰u lÃ  cao hÆ¡n")
        
        # Hiá»ƒn thá»‹ dÃ²ng Ä‘á»ƒ nháº­p káº¿t quáº£ thá»±c táº¿
        print("káº¿t quáº£ Ä‘Ãºng: ", end="", flush=True)
        
        return {"input": inp, "predictions": {ml: res[0]}}
    else:
        print("âŒ Thuáº­t toÃ¡n khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng Ä‘Æ°á»£c há»— trá»£")
        print("ğŸ“‹ CÃ¡c lá»±a chá»n: svr, rf, nn, xgb, lr, gb, ensemble, all")
        return False

def predict(inp, ml):
    """HÃ m predict gá»‘c - gá»i enhanced_predict Ä‘á»ƒ cÃ³ thÃªm tÃ­nh nÄƒng"""
    return enhanced_predict(inp, ml)